# -*- coding: utf-8 -*-
"""autoencoder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OMkR6PxoiSY594sxbQkJbDRbig5LQSXU
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install graphviz

from    keras.utils.vis_utils    import plot_model

import tensorflow as tf
import tensorflow.keras as keras
import tensorflow_datasets as tfds
import pandas as pd
import os
from tensorflow.python.keras.utils.vis_utils import plot_model
import torch
import torchvision
from torch import nn
from torch.autograd import Variable
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.utils import save_image
from torchvision.datasets import MNIST


from torch.utils.data import DataLoader
import numpy as np
import matplotlib.pyplot as plt
from IPython import display
import os
import cv2
from imutils import paths
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Model
from tensorflow.python.keras.utils.vis_utils import plot_model
import torch
from torch import nn
from tqdm.auto import tqdm
from torchvision import transforms
from sklearn.model_selection import train_test_split

tf.config.run_functions_eagerly(True)

def plot_results(images, n_cols=None):
    '''visualizes fake images'''
    display.clear_output(wait=False)  

    n_cols = n_cols or len(images)
    n_rows = (len(images) - 1) // n_cols + 1

    if images.shape[-1] == 1:
        images = np.squeeze(images, axis=-1)

    plt.figure(figsize=(n_cols, n_rows))
    
    for index, image in enumerate(images):
        plt.subplot(n_rows, n_cols, index + 1)
        plt.imshow(image, cmap="binary")
        plt.axis("off")

"""# 载入数据"""

img_path = '/content/drive/MyDrive/Colab Notebooks/fianl_project/dataset/contours3/'
print("[INFO] 开始读取数据")
data_contour = []

img_list=os.listdir(img_path)
img_list.sort()
img_list.sort(key = lambda x: int(x[:-4])) ##文件名按数字排序
img_nums=len(img_list)
sorted_list=[]
for i in range(img_nums):
    img_name=img_path+img_list[i]
    sorted_list.append(img_name)
    #print(img_name)

def map_image(image, label):
  '''Normalizes the image. Returns image as input and label.'''
  image = tf.cast(image, dtype=tf.float32)
  image = image / 255.0

  return image, image

# 3 遍历读取数据
data_contour = []
img_size=300
for imagePath in sorted_list:
    # 3.1 读取图像数据，由于使用神经网络，需要给定成一维
    #print(imagePath)
    image = cv2.imread(imagePath,0)   #读取图像
    image = np.array(image, dtype="float") / 255.0
    #print(image.shape)
    image=cv2.resize(image,(img_size,img_size))
    data_contour.append(image)   #在data的末尾，追加image数据

plt.imshow(data_contour[100])

len(data_contour)

initial_img1=np.expand_dims(np.array(data_contour[100]), axis=0)
initial_img3=np.expand_dims(np.array(data_contour[400]), axis=0)

initial_img1=np.repeat(initial_img1,540, axis=0)
#initial_img2=np.repeat(initial_img2,900, axis=0)

X_train_initia1l=initial_img1[0:420]
X_train_initial1=np.reshape(X_train_initia1l,(-1,img_size,img_size,1))
X_test_initial1=initial_img1[0:120]
print(X_test_initial1.shape)
X_test_initial1=np.reshape(X_test_initial1,(-1,img_size,img_size,1))

initial_img3=np.repeat(initial_img3,540, axis=0)
X_train_initia13=initial_img3[0:420]
X_train_initial3=np.reshape(X_train_initia13,(-1,img_size,img_size,1))
X_test_initial3=initial_img3[0:120]
X_test_initial3=np.reshape(X_test_initial3,(-1,img_size,img_size,1))



a=np.reshape(X_train_initial3[403],(img_size,img_size))
plt.imshow(a)

data_contours=np.array(data_contour)
#data_contours=np.random.shuffle(data_contours)

data_contours.shape

signal=pd.read_csv("/content/drive/MyDrive/Colab Notebooks/fianl_project/dataset/markersensortrail1all.csv")
#signal.head(5)
signal=np.array(signal)
signal=signal[360:,1:]
def normalization(data):
    range = np.max(data) - np.min(data)
    return (data - np.min(data)) / range
signal_data1=normalization(signal-signal[100])
signal_data2=normalization(signal-signal[400])

X_train1, X_test1, y_train, y_test = train_test_split(signal_data1, data_contours, test_size=0.221, random_state=42)

X_train1.shape

y_train=np.reshape(y_train,(-1,img_size,img_size,1))
y_test=np.reshape(y_test,(-1,img_size,img_size,1))

y_test.shape

data_contour=np.array(data_contour[0:900])

cc=np.reshape(y_train[12],[300,300])
plt.imshow(cc)



"""## 构建tensorflow 数据集

# 建立模型

## 100*100 尝试
"""

def encoder(inputs):
  '''Defines the encoder with two Conv2D and max pooling layers.'''
  conv_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same',)(inputs)
  max_pool_1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv_1)

  conv_2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same')(max_pool_1)
  max_pool_2 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv_2)
  conv_3 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(max_pool_2)
  max_pool_3 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv_3)
  return max_pool_2

def bottle_neck(input_img,input_signal):
  '''Defines the bottleneck.'''
  bottle_neck = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(input_img)
  input_img=tf.keras.layers.Flatten()(bottle_neck)
  input_siganl=tf.keras.layers.Flatten()(input_signal)
  inputs=tf.concat([input_img,input_signal],1)
  bottle_neck1=tf.keras.layers.Dense(20000, activation='relu')(inputs)
  encoder_visualization = tf.keras.layers.Conv2D(filters=1, kernel_size=(3,3), activation='sigmoid', padding='same')(bottle_neck)
  return bottle_neck1, encoder_visualization

def decoder(inputs):
  '''Defines the decoder path to upsample back to the original image size.'''
  inputs=tf.reshape(inputs,[-1,25,25,32])
  conv_1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same')(inputs)
  up_sample_1 = tf.keras.layers.UpSampling2D(size=(2,2))(conv_1)

  conv_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(up_sample_1)
  up_sample_2 = tf.keras.layers.UpSampling2D(size=(2,2))(conv_2)

  conv_3 = tf.keras.layers.Conv2D(filters=1, kernel_size=(3,3), activation='sigmoid', padding='same')(up_sample_2)

  return conv_3

def convolutional_auto_encoder():
  '''Builds the entire autoencoder model.'''
  inputs = tf.keras.layers.Input(shape=(100, 100, 1,))
  inputs2= tf.keras.layers.Input(shape=(4))
  encoder_output = encoder(inputs)
  bottleneck_output, encoder_visualization = bottle_neck(encoder_output,inputs2)
  decoder_output = decoder(bottleneck_output)
  model = tf.keras.Model(inputs =[inputs,inputs2], outputs=decoder_output)
  encoder_model = tf.keras.Model(inputs=[inputs,inputs2], outputs=encoder_visualization)
  return model, encoder_model

convolutional_model, convolutional_encoder_model = convolutional_auto_encoder()
convolutional_model.summary()

plot_model(convolutional_model, to_file="model.png",show_shapes=True)

BATCH_SIZE = 30
train_steps = 630 // BATCH_SIZE
valid_steps = 270 // BATCH_SIZE

convolutional_model.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy')

conv_model_history = convolutional_model.fit([X_train_initial,y_train],X_train, steps_per_epoch=train_steps, validation_data=([X_test_initial,y_test],X_test), validation_steps=valid_steps, epochs=100)

def display_one_row(disp_images, offset, shape=(img_size, img_size)):
  '''Display sample outputs in one row.'''
  for idx, test_image in enumerate(disp_images):
    plt.subplot(3, 10, offset + idx + 1)
    plt.xticks([])
    plt.yticks([])
    test_image = np.reshape(test_image, shape)
    plt.imshow(test_image, cmap='gray')


def display_results(disp_input_images, disp_predicted,disp_expect, enc_shape=(8,4)):
  '''Displays the input, encoded, and decoded output values.'''
  plt.figure(figsize=(15, 5))
  display_one_row(disp_input_images, 0, shape=(img_size,img_size,))
  #display_one_row(disp_encoded, 10, shape=enc_shape)
  display_one_row(disp_expect, 10, shape=(img_size,img_size,))
  display_one_row(disp_predicted, 20, shape=(img_size,img_size,))

# take 1 batch of the dataset
#test_dataset = test_dataset.take(1)

# take the input images and put them in a list
# output_samples = []
# for input_image in tfds.as_numpy(X_test):
#       output_samples = input_image
output_samples=y_test
# pick 10 indices
i=30
idxs = np.array([1+i, 2+i, 3+i, 4+i, 5+i, 6+i, 7+i, 8+i, 9+i, 10+i])

# prepare test samples as a batch of 10 images
conv_output_samples = np.array(output_samples[idxs])
conv_output_samples = np.reshape(conv_output_samples, (10,img_size,img_size, 1))
test_input_samples1=np.array(X_test_initial1[idxs])
test_input_samples_img1 = np.reshape(test_input_samples1, (10,img_size,img_size, 1))
test_input_samples3=np.array(X_test_initial3[idxs])
test_input_samples_img3 = np.reshape(test_input_samples3, (10,img_size,img_size, 1))
test_input_sample_signal1=np.array(X_test1[idxs])
test_input_sample_signal2=np.array(X_test2[idxs])
# get the encoder ouput
#encoded = convolutional_encoder_model.predict([test_input_samples_img,test_input_sample_signal])

# get a prediction for some values in the dataset
predicted = convolutional_model.predict([test_input_samples_img1,test_input_sample_signal1,test_input_samples_img3,test_input_sample_signal2])

# display the samples, encodings and decoded values!
display_results(test_input_samples1,predicted,conv_output_samples, enc_shape=(7,7))

output_samples=X_test
# pick 10 indices
idxs = np.array([1])
conv_output_samples = np.array(output_samples[idxs])
conv_output_samples = np.reshape(conv_output_samples, (1, 28, 28, 1))
predicted = convolutional_model.predict(conv_output_samples)
display_one_row(predicted, 20, shape=(28,28,))

"""# 300*300尝试"""

def encoder(inputs):
  '''Defines the encoder with two Conv2D and max pooling layers.'''
  inputs=tf.keras.layers.GaussianNoise(0.1)(inputs)
  conv_1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(10,10), activation='relu', padding='same',strides=2)(inputs)
  max_pool_1 = tf.keras.layers.MaxPooling2D(pool_size=(3,3))(conv_1)

  conv_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), activation='relu', padding='same',strides=2)(max_pool_1)
  max_pool_2 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv_2)
  conv_3 = tf.keras.layers.Conv2D(filters=64, kernel_size=(4,4), activation='relu', padding='same',strides=2)(max_pool_2)
  max_pool_3 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv_3)
  return max_pool_2

def bottle_neck(input_img,input_signal):
  '''Defines the bottleneck.'''
  bottle_neck = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(input_img)
  input_img=tf.keras.layers.Flatten()(bottle_neck)
  input_siganl=tf.keras.layers.Flatten()(input_signal)
  input_siganl=tf.keras.layers.Dense(100, activation='relu')(input_siganl)
  inputs=tf.concat([input_img,input_signal],1)
  bottle_neck1=tf.keras.layers.Dense(2500, activation='relu')(inputs)
  bottle_neck2=tf.keras.layers.Dense(2500, activation='relu')(bottle_neck1)
  return bottle_neck2

def decoder(inputs1):
  '''Defines the decoder path to upsample back to the original image size.'''
  inputs=inputs1
  inputs=tf.reshape(inputs,[-1,25,25,4])
  conv_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(4,4), activation='relu', padding='same')(inputs)
  up_sample_1 = tf.keras.layers.UpSampling2D(size=(3,3))(conv_1)

  conv_2 = tf.keras.layers.Conv2D(filters=32, kernel_size=(4,4), activation='relu', padding='same')(up_sample_1)
  up_sample_2 = tf.keras.layers.UpSampling2D(size=(2,2))(conv_2)

  conv_3 = tf.keras.layers.Conv2D(filters=16, kernel_size=(4,4), activation='relu', padding='same')(up_sample_2)
  up_sample_3 = tf.keras.layers.UpSampling2D(size=(2,2))(conv_3)

  conv_4 = tf.keras.layers.Conv2D(filters=1, kernel_size=(3,3), activation='sigmoid', padding='same')(up_sample_3)


  return conv_4

def convolutional_auto_encoder():
  '''Builds the entire autoencoder model.'''
  inputs1 = tf.keras.layers.Input(shape=(300, 300, 1,))
  inputs2= tf.keras.layers.Input(shape=(3))
  encoder_output1 = encoder(inputs1)
  bottleneck_output1= bottle_neck(encoder_output1,inputs2)
  decoder_output = decoder(bottleneck_output1)
  model = tf.keras.Model(inputs =[inputs1,inputs2], outputs=decoder_output)
  
  return model

convolutional_model= convolutional_auto_encoder()
convolutional_model.summary()

def VGGloss(y_true, y_pred):  # Note the parameter order
    from keras.applications.vgg16 import VGG16
    mod = VGG16(include_top=False, weights='imagenet')
    vggmodel = mod 
    f_p = vggmodel(y_pred)  
    f_t = vggmodel(y_true)  
    return K.mean(K.square(f_p - f_t))

BATCH_SIZE = 30
train_steps = 420 // BATCH_SIZE
valid_steps = 120 // BATCH_SIZE
convolutional_model.compile(optimizer=tf.keras.optimizers.Adam(), loss ="BinaryCrossentropy")

conv_model_history = convolutional_model.fit([X_train_initial1,X_train1],y_train, steps_per_epoch=train_steps, validation_data=([X_test_initial1,X_test1],y_test), validation_steps=valid_steps, epochs=100)

plot_model(model,to_file='model1.png',show_shapes=True,show_layer_names=True,rankdir='TB')

convolutional_model.save(r'/content/drive/MyDrive/Colab Notebooks/fianl_project/model/model300.h5')

convolutional_model = tf.keras.models.load_model(r'/content/drive/MyDrive/Colab Notebooks/fianl_project/model/model300.h5')

output_samples=y_test
# pick 10 indices
i=40
idxs = np.array([1+i, 2+i, 3+i, 4+i, 5+i, 6+i, 7+i, 8+i, 9+i, 10+i])

# prepare test samples as a batch of 10 images
conv_output_samples = np.array(output_samples[idxs])
conv_output_samples = np.reshape(conv_output_samples, (-1,img_size,img_size, 1))
test_input_samples1=np.array(X_test_initial1[idxs])
test_input_samples_img1 = np.reshape(test_input_samples1, (-1,img_size,img_size, 1))
test_input_sample_signal1=np.array(X_test1[idxs])

# get the encoder ouput
#encoded = convolutional_encoder_model.predict([test_input_samples_img,test_input_sample_signal])

# get a prediction for some values in the dataset
predicted = convolutional_model.predict([test_input_samples_img1,test_input_sample_signal1])

# display the samples, encodings and decoded values!
#display_results(test_input_samples1,predicted,conv_output_samples, enc_shape=(7,7))
#encoded = convolutional_encoder_model.predict([test_input_samples_img,test_input_sample_signal])

# get a prediction for some values in the dataset


# display the samples, encodings and decoded values!
display_results(test_input_samples1,predicted,conv_output_samples, enc_shape=(7,7))

def display_one_row(disp_images, offset, shape=(img_size, img_size)):
  '''Display sample outputs in one row.'''
  for idx, test_image in enumerate(disp_images):
    plt.subplot(3, 10, offset + idx + 1)
    plt.xticks([])
    plt.yticks([])
    test_image = np.reshape(test_image, shape)
    plt.imshow(test_image, cmap='gray')


def display_results(disp_input_images, disp_predicted,disp_expect, enc_shape=(8,4)):
  '''Displays the input, encoded, and decoded output values.'''
  plt.figure(figsize=(15, 5))
  display_one_row(disp_input_images, 0, shape=(img_size,img_size,))
  #display_one_row(disp_encoded, 10, shape=enc_shape)
  display_one_row(disp_expect, 10, shape=(img_size,img_size,))
  display_one_row(disp_predicted, 20, shape=(img_size,img_size,))
# take 1 batch of the dataset
#test_dataset = test_dataset.take(1)

# take the input images and put them in a list
# output_samples = []
# for input_image in tfds.as_numpy(X_test):
#       output_samples = input_image
output_samples=data_contours
# pick 10 indices
i=20
idxs = np.array([i])

# prepare test samples as a batch of 10 images
conv_output_samples = np.array(output_samples[idxs])
conv_output_samples = np.reshape(conv_output_samples, (1,img_size,img_size, 1))
test_input_samples1=np.array(X_test_initial1[idxs])
test_input_samples_img1 = np.reshape(test_input_samples1, (1,img_size,img_size, 1))
test_input_sample_signal1=np.array(signal_data[idxs])

# get the encoder ouput
#encoded = convolutional_encoder_model.predict([test_input_samples_img,test_input_sample_signal])

# get a prediction for some values in the dataset
predicted = convolutional_model.predict([test_input_samples_img1,test_input_sample_signal1])

# display the samples, encodings and decoded values!
#display_results(test_input_samples1,predicted,conv_output_samples, enc_shape=(7,7))
predicteds=np.reshape(predicted,[300,300])
conv_output_samples=np.reshape(conv_output_samples,[300,300])
plt.subplot(1,2,1)
plt.title('predicted_img',color='blue') 
plt.imshow(predicteds)
plt.subplot(1,2,2)
plt.imshow(conv_output_samples)
plt.title('initial_img',color='blue')

"""# IOU pipeline"""

def binary(img,thresh):
  height, width = img.shape[0:2]
  for row in range(height):
    for col in range(width):
        # 获取到灰度值
        gray = img[row, col]
        # 如果灰度值高于阈值 就等于255最大值
        if gray > thresh:
            img[row, col] = 1
        # 如果小于阈值，就直接改为0
        elif gray < thresh:
            img[row, col] = 0
  return img
predicteds=predicteds*255
conv_output_samples=conv_output_samples*255
predicteds=binary(predicteds,60)
conv_output_samples=binary(conv_output_samples,60)
plt.subplot(1,2,1)
#plt.title('predicted_img',color='blue') 
plt.imshow(predicteds)
plt.subplot(1,2,2)
#plt.title('initial_img',color='blue') 
plt.imshow(conv_output_samples)

def IOU(y_true, y_pred):
        """
        y_true: Tensor，真实标签（one-hot类型），
        y_pred: Tensor，模型输出结果（one-hot类型），二者shape都为[N,H,W,C]或[N,H*W,C],C为总类别数,
        """
        y_true = y_true.reshape(1,-1) # 求argmax后，展平为一维
        y_pred = y_pred.reshape(1,-1)
        intersection = np.sum(np.multiply(y_true.astype('bool'),y_pred == 1))
        union = np.sum((y_true.astype('bool')+y_pred.astype('bool'))>0) 
        return intersection/union
num_classes=2
iou=IOU(predicteds,conv_output_samples)
iou

y_test.shape[0]

y_test.shape

iou_sum=0
false_count_075=[]
false_count_060=[]
false_count_090=[]
false_count_nb=[]
for i in range(0,y_test.shape[0]):
  output_samples=y_test
  # pick 10 indices
  idxs = np.array([i])

  # prepare test samples as a batch of 10 images
  conv_output_samples = np.array(output_samples[idxs])
  conv_output_samples = np.reshape(conv_output_samples, (1,img_size,img_size, 1))
  test_input_samples1=np.array(initial_img1[idxs])
  test_input_samples_img1 = np.reshape(test_input_samples1, (1,img_size,img_size, 1))
  test_input_sample_signal1=np.array(X_test1[idxs])

  # get the encoder ouput
  #encoded = convolutional_encoder_model.predict([test_input_samples_img,test_input_sample_signal])

  # get a prediction for some values in the dataset
  predicted = convolutional_model.predict([test_input_samples_img1,test_input_sample_signal1])

  # display the samples, encodings and decoded values!
  #display_results(test_input_samples1,predicted,conv_output_samples, enc_shape=(7,7))
  predicteds=np.reshape(predicted,[300,300])
  conv_output_samples=np.reshape(conv_output_samples,[300,300])
  predicteds=predicteds*255
  conv_output_samples=conv_output_samples*255
  # display the samples, encodings and decoded values!
  #display_results(test_input_samples,predicted,conv_output_samples, enc_shape=(7,7))
  predicteds=binary(predicteds,60)
  #print("the current one is ",i)
  conv_output_samples=binary(conv_output_samples,60)
  iou=IOU(predicteds,conv_output_samples)
  #print("the current img's iou is",iou)
  iou_sum=iou_sum+iou
  if(iou>0.90):false_count_nb.append(i)
  if(iou<0.75 and iou>0.6):false_count_075.append(i)
  if(iou<0.90 and iou>0.75):false_count_090.append(i)
  if(iou<0.60):false_count_060.append(i)
miou=iou_sum/y_test.shape[0]

print("the performance too bad at,below 60")
for idx in false_count_060:
  print(idx)



print("the mean of iou is ",miou)
print("the num that NB is ",len(false_count_nb))
print("the num that can't meet the 90 demand is ",len(false_count_090))
print("the num that can't meet the 75 demand is ",len(false_count_075))
print("the num that can't meet the 60 demand is ",len(false_count_060))

def get_rectangle_coord(img):
  img=img*255
  coord=[]
  img= np.array(img, dtype=np.uint8)
  # cv2.threshold：参数1是源图片, 参数2是阈值, 参数3是填充色, 参数4是阈值类型
  ret, thresh = cv2.threshold(img, 60, 255, cv2.THRESH_BINARY)
  black = cv2.cvtColor(np.zeros((img.shape[1], img.shape[0]), dtype=np.uint8), cv2.COLOR_GRAY2BGR)

  contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

  for cnt in contours:
    
    if (cv2.contourArea(cnt) < 2000 ):
        continue
    x, y, w, h = cv2.boundingRect(cnt)
    epsilon = 0.01 * cv2.arcLength(cnt,True)
    # cv2.approxPolyDP：参数1是轮廓，参数2是epsilon值，表源轮廓与近似多边形的最大差值，参数3是布尔标记，表示多边形是否闭合
    approx = cv2.approxPolyDP(cnt,epsilon,True)
    hull = cv2.convexHull(cnt) # 获取处理过的轮廓信息
    cv2.drawContours(black, [cnt], -1, (0, 255, 0), thickness=-1)
    coord.append([x,y])
    #cv2.drawContours(black, [approx], -1, (255, 255, 0), 2)
    #cv2.drawContours(black, [hull], -1, (0, 0, 255), 2)
#     kernel = np.ones(shape=[1,1],dtype=np.uint8)
#     black = cv2.erode(black,kernel=kernel)  # 腐蚀操作
  return coord,black

def coord_loss(cores1,cores2):
  loss=0.542*abs(cores1-cores2)
  return loss

cores3,mask3=get_rectangle_coord(predicteds)
print("the coordinate of predicted image is \n",cores3)
plt.imshow(mask3)

cores1,mask1=get_rectangle_coord(predicteds)
cores2,mask2=get_rectangle_coord(conv_output_samples)
cores1=np.array(cores1)
cores2=np.array(cores2)
loss=coord_loss(cores1,cores2)
plt.subplot(1,2,1)
plt.title('predicted_img',color='blue') 
plt.imshow(mask1)
plt.subplot(1,2,2)
plt.title('initial_img',color='blue') 
plt.imshow(mask2)

print("the coordinate of predicted image is \n",cores1)
print("the coordinate of initail image is \n",cores2)
print("the loss of coordinate is \n",loss)

losses=[]
for i in range(0,len(signal_data1)):

  output_samples=data_contours
  # pick 10 indices
  idxs = np.array([i])

  # prepare test samples as a batch of 10 images
  conv_output_samples = np.array(output_samples[idxs])
  conv_output_samples = np.reshape(conv_output_samples, (1,img_size,img_size, 1))
  test_input_samples1=np.array(initial_img1[idxs])
  test_input_samples_img1 = np.reshape(test_input_samples1, (1,img_size,img_size, 1))
  test_input_sample_signal1=np.array(signal_data1[idxs])

  # get the encoder ouput
  #encoded = convolutional_encoder_model.predict([test_input_samples_img,test_input_sample_signal])

  # get a prediction for some values in the dataset
  predicted = convolutional_model.predict([test_input_samples_img1,test_input_sample_signal1])

  # display the samples, encodings and decoded values!
  #display_results(test_input_samples1,predicted,conv_output_samples, enc_shape=(7,7))
  predicteds=np.reshape(predicted,[300,300])
  conv_output_samples=np.reshape(conv_output_samples,[300,300])
  predicteds=predicteds*255
  conv_output_samples=conv_output_samples*255
  # display the samples, encodings and decoded values!
  #display_results(test_input_samples,predicted,conv_output_samples, enc_shape=(7,7))
  predicteds=binary(predicteds,60)
  #print("the current one is ",i)
  conv_output_samples=binary(conv_output_samples,60)
  cores1,mask1=get_rectangle_coord(predicteds)
  cores2,mask2=get_rectangle_coord(conv_output_samples)
  cores1=np.array(cores1)
  cores2=np.array(cores2)
  loss=coord_loss(cores1,cores2)
  losses.append(loss)
  # print("the coordinate of predicted image is \n",cores1)
  # print("the coordinate of initail image is \n",cores2)
  # print("the loss of coordinate is \n",loss)
  # show_loss(loss)

losses=np.array(losses)
losses=losses.reshape(540,2)
losses.shape

np.mean(losses,axis=0)

"""#获取矩形坐标 pipeline"""

def findcore(coordinates):
  cores=[]
  for coordinate in coordinates:
    x = coordinate[0]+coordinate[2]/2
    y = coordinate[1]+coordinate[3]/2
    cores.append([x,y])
    
  return np.array(cores)
def get_rectangle_coord(img):
  img=img*255
  img= np.array(img, dtype=np.uint8)
  mask = np.zeros(img.shape,dtype=np.uint8)
  ret, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)
  mask = np.zeros(img.shape,dtype=np.uint8)
  contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)
  cv_contours = []
  coordinates=[]
  num=0
  for contour in contours:
      area = cv2.contourArea(contour)
      if area <= 500 and area>=70:
        #cv_contours.append(contour)
        x, y, w, h = cv2.boundingRect(contour)
        if(x+w<240 and h<40):
          cv2.drawContours(mask, contour, -1, (255), 1)
          coordinates.append([x,y,w,h])
          num=num+1
      else:
          continue
  print(num)
  cores=findcore(coordinates)
  return cores,mask
def coord_loss(cores1,cores2):
  loss=abs(cores1-cores2)/cores2
  return loss
def show_loss(losss):
  for i in range(0,4):
    print("the loss of x{} is {}%,the loss of y{} is {}%".format(i,losss[i][0]*100,i,losss[i][1]*100))

coords=[]

cores3,mask3=get_rectangle_coord(stright_line)
print("the coordinate of predicted image is \n",cores3)
plt.imshow(mask3)

cores3[:,0]

cores1,mask1=get_rectangle_coord(predicteds)
cores2,mask2=get_rectangle_coord(conv_output_samples)
cores1=np.array(cores1)
cores2=np.array(cores2)
loss=coord_loss(cores1,cores2)
plt.subplot(1,2,1)
plt.title('predicted_img',color='blue') 
plt.imshow(mask1)
plt.subplot(1,2,2)
plt.title('initial_img',color='blue') 
plt.imshow(mask2)

print("the coordinate of predicted image is \n",cores1)
print("the coordinate of initail image is \n",cores2)
print("the loss of coordinate is \n",loss)
show_loss(loss)

coords.append(cores1)

coords=np.array(coords)

coords[1].shape

for i in range(1,4):
  print(coords[1])

"""## 像素转化为毫米/pixels to mm"""

def get_refer(coord):
  refer=[]
  trans_factor=0.542
  for i in range(1,4):
    dis_x=(coord[0][0]-coord[i][0])*trans_factor
    dis_y=(coord[0][1]-coord[i][1])*trans_factor
    refer.append([dis_x,dis_y])
  refer.append([0,0])
  return refer
refer=np.array(get_refer(cores2))
refer=np.sort(refer,axis=0)
refer

refer[:,1]

"""## interpolation"""

# -*-coding:utf-8 -*-
import numpy as np
from scipy import interpolate
import pylab as pl

x=refer[:,0]
#x=[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]
y=refer[:,1]
xnew=np.linspace(0,76,num=50)
pl.plot(x,y,"ro")

for kind in ["nearest","zero","slinear"]:#插值方式
    #"nearest","zero"为阶梯插值
    #slinear 线性插值
    #"quadratic","cubic" 为2阶、3阶B样条曲线插值
    f=interpolate.interp1d(x,y,kind=kind)
    # ‘slinear’, ‘quadratic’ and ‘cubic’ refer to a spline interpolation of first, second or third order)
    ynew=f(xnew)
    pl.plot(xnew,ynew,label=str(kind))
pl.legend(loc="lower right")
pl.show()

"""# 以传感器为输入

## another vision tensorflow autoencoder VAE
"""

import tensorflow as tf
import tensorflow_datasets as tfds

import matplotlib.pyplot as plt
import numpy as np

import os
import zipfile
import urllib.request
import random
from IPython import display

# set a random seed
np.random.seed(51)

# parameters for building the model and training
BATCH_SIZE=2000
LATENT_DIM=512
IMAGE_SIZE=64

# make the data directory
try:
  os.mkdir('/tmp/anime')
except OSError:
  pass

# download the zipped dataset to the data directory
data_url = "https://storage.googleapis.com/laurencemoroney-blog.appspot.com/Resources/anime-faces.zip"
data_file_name = "animefaces.zip"
download_dir = '/tmp/anime/'
urllib.request.urlretrieve(data_url, data_file_name)

# extract the zip file
zip_ref = zipfile.ZipFile(data_file_name, 'r')
zip_ref.extractall(download_dir)
zip_ref.close()

# Data Preparation Utilities

def get_dataset_slice_paths(image_dir):
  '''returns a list of paths to the image files'''
  image_file_list = os.listdir(image_dir)
  image_paths = [os.path.join(image_dir, fname) for fname in image_file_list]

  return image_paths


def map_image(image_filename):
  '''preprocesses the images'''
  img_raw = tf.io.read_file(image_filename)
  image = tf.image.decode_jpeg(img_raw)

  image = tf.cast(image, dtype=tf.float32)
  image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))
  image = image / 255.0  
  image = tf.reshape(image, shape=(IMAGE_SIZE, IMAGE_SIZE, 3,))

  return image

# get the list containing the image paths
paths = get_dataset_slice_paths("/tmp/anime/images/")

# shuffle the paths
random.shuffle(paths)

# split the paths list into to training (80%) and validation sets(20%).
paths_len = len(paths)
train_paths_len = int(paths_len * 0.8)

train_paths = paths[:train_paths_len]
val_paths = paths[train_paths_len:]

# load the training image paths into tensors, create batches and shuffle
training_dataset = tf.data.Dataset.from_tensor_slices((train_paths))
training_dataset = training_dataset.map(map_image)
training_dataset = training_dataset.shuffle(1000).batch(BATCH_SIZE)

# load the validation image paths into tensors and create batches
validation_dataset = tf.data.Dataset.from_tensor_slices((val_paths))
validation_dataset = validation_dataset.map(map_image)
validation_dataset = validation_dataset.batch(BATCH_SIZE)


print(f'number of batches in the training set: {len(training_dataset)}')
print(f'number of batches in the validation set: {len(validation_dataset)}')

def display_faces(dataset, size=9):
  '''Takes a sample from a dataset batch and plots it in a grid.'''
  dataset = dataset.unbatch().take(size)
  n_cols = 3
  n_rows = size//n_cols + 1
  plt.figure(figsize=(5, 5))
  i = 0
  for image in dataset:
    i += 1
    disp_img = np.reshape(image, (64,64,3))
    plt.subplot(n_rows, n_cols, i)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(disp_img)


def display_one_row(disp_images, offset, shape=(28, 28)):
  '''Displays a row of images.'''
  for idx, image in enumerate(disp_images):
    plt.subplot(3, 10, offset + idx + 1)
    plt.xticks([])
    plt.yticks([])
    image = np.reshape(image, shape)
    plt.imshow(image)


def display_results(disp_input_images, disp_predicted):
  '''Displays input and predicted images.'''
  plt.figure(figsize=(15, 5))
  display_one_row(disp_input_images, 0, shape=(IMAGE_SIZE,IMAGE_SIZE,3))
  display_one_row(disp_predicted, 20, shape=(IMAGE_SIZE,IMAGE_SIZE,3))

display_faces(validation_dataset, size=12)





"""## 1.sampling class

"""

class Sampling(tf.keras.layers.Layer):
  def call(self, inputs):
    """Generates a random sample and combines with the encoder output
    
    Args:
      inputs -- output tensor from the encoder

    Returns:
      `inputs` tensors combined with a random sample
    """
    ### START CODE HERE ###
    mu, sigma = inputs
    batch = tf.shape(mu)[0]
    dim = tf.shape(mu)[1]
    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))
    z = mu + tf.exp(0.5 * sigma) * epsilon
    ### END CODE HERE ###
    return  z

def encoder_layers(inputs, latent_dim):
  """Defines the encoder's layers.
  Args:
    inputs -- batch from the dataset
    latent_dim -- dimensionality of the latent space

  Returns:
    mu -- learned mean
    sigma -- learned standard deviation
    batch_3.shape -- shape of the features before flattening
  """
  ### START CODE HERE ###
  x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2, padding="same", activation='relu', name="encode_conv1")(inputs)
  x = tf.keras.layers.BatchNormalization()(x)

  x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', name="encode_conv2")(x)
  x = tf.keras.layers.BatchNormalization()(x)

  x = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2, padding='same', activation='relu', name="encode_conv3")(x)
  batch_3 = tf.keras.layers.BatchNormalization()(x)   

  x = tf.keras.layers.Flatten(name="encode_flatten")(batch_3)
  x = tf.keras.layers.Dense(1024, activation='relu', name="encode_dense")(x)

  x = tf.keras.layers.BatchNormalization()(x)
  mu = tf.keras.layers.Dense(latent_dim, name='latent_mu')(x)
  sigma = tf.keras.layers.Dense(latent_dim, name ='latent_sigma')(x)
  ### END CODE HERE ###

  # revise `batch_3.shape` here if you opted not to use 3 Conv2D layers
  return mu, sigma, batch_3.shape

def encoder_model(latent_dim, input_shape):
  """Defines the encoder model with the Sampling layer
  Args:
    latent_dim -- dimensionality of the latent space
    input_shape -- shape of the dataset batch

  Returns:
    model -- the encoder model
    conv_shape -- shape of the features before flattening
  """
  ### START CODE HERE ###
  inputs = tf.keras.layers.Input(shape=input_shape)
  mu, sigma, conv_shape = encoder_layers(inputs, latent_dim=LATENT_DIM)
  z = Sampling()((mu, sigma))
  model = tf.keras.Model(inputs, outputs=[mu, sigma, z])
  ### END CODE HERE ###
  model.summary()
  return model, conv_shape

def decoder_layers(inputs, conv_shape):
  """Defines the decoder layers.
  Args:
    inputs -- output of the encoder 
    conv_shape -- shape of the features before flattening

  Returns:
    tensor containing the decoded output
  """
  ### START CODE HERE ###
  units = conv_shape[1] * conv_shape[2] * conv_shape[3]
  x = tf.keras.layers.Dense(units, activation = 'relu', name="decode_dense1")(inputs)
  x = tf.keras.layers.BatchNormalization()(x)
  x = tf.keras.layers.Reshape((conv_shape[1], conv_shape[2], conv_shape[3]), name="decode_reshape")(x)

  x = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='same', activation='relu', name="decode_conv2d_1")(x)
  x = tf.keras.layers.BatchNormalization()(x)
  
  x = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', name="decode_conv2d_12")(x)
  x = tf.keras.layers.BatchNormalization()(x)
  
  x = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='relu', name="decode_conv2d_2")(x)
  x = tf.keras.layers.BatchNormalization()(x) 

  x = tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=1, strides=1, padding='same', activation='sigmoid', name="decode_final")(x)
  ### END CODE HERE ###
  return x

def decoder_model(latent_dim, conv_shape):
  """Defines the decoder model.
  Args:
    latent_dim -- dimensionality of the latent space
    conv_shape -- shape of the features before flattening

  Returns:
    model -- the decoder model
  """
  ### START CODE HERE ###
  inputs = tf.keras.layers.Input(shape=(latent_dim,))
  outputs = decoder_layers(inputs, conv_shape)
  model = tf.keras.Model(inputs, outputs)
  ### END CODE HERE ###
  model.summary()
  return model

def kl_reconstruction_loss(inputs, outputs, mu, sigma):
  """ Computes the Kullback-Leibler Divergence (KLD)
  Args:
    inputs -- batch from the dataset
    outputs -- output of the Sampling layer
    mu -- mean
    sigma -- standard deviation

  Returns:
    KLD loss
  """
  kl_loss = 1 + sigma - tf.square(mu) - tf.math.exp(sigma)
  return tf.reduce_mean(kl_loss) * -0.5

def vae_model(encoder, decoder, input_shape):
  """Defines the VAE model
  Args:
    encoder -- the encoder model
    decoder -- the decoder model
    input_shape -- shape of the dataset batch

  Returns:
    the complete VAE model
  """
  ### START CODE HERE ###
  inputs = tf.keras.layers.Input(shape=input_shape)

  # get mu, sigma, and z from the encoder output
  mu, sigma, z = encoder(inputs)
  
  # get reconstructed output from the decoder
  reconstructed = decoder(z)

  # define the inputs and outputs of the VAE
  model = tf.keras.Model(inputs=inputs, outputs=reconstructed)

  # add the KL loss
  loss = kl_reconstruction_loss(inputs, z, mu, sigma)
  model.add_loss(loss)
  ### END CODE HERE ###
  return model

def get_models(input_shape, latent_dim):
  """Returns the encoder, decoder, and vae models"""
  ### START CODE HERE ###
  encoder, conv_shape = encoder_model(latent_dim=latent_dim, input_shape=input_shape)
  decoder = decoder_model(latent_dim=latent_dim, conv_shape=conv_shape)
  vae = vae_model(encoder, decoder, input_shape=input_shape)
  ### END CODE HERE ###
  return encoder, decoder, vae

encoder, decoder, vae = get_models(input_shape=(300,300,1,), latent_dim=LATENT_DIM)

optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)
loss_metric = tf.keras.metrics.Mean()
mse_loss = tf.keras.losses.MeanSquaredError()
bce_loss = tf.keras.losses.BinaryCrossentropy()

def generate_and_save_images(model, epoch, step, test_input):
  """Helper function to plot our 16 images

  Args:

  model -- the decoder model
  epoch -- current epoch number during training
  step -- current step number during training
  test_input -- random tensor with shape (16, LATENT_DIM)
  """
  predictions = model.predict(test_input)

  fig = plt.figure(figsize=(4,4))

  for i in range(predictions.shape[0]):
      plt.subplot(4, 4, i+1)
      img = predictions[i, :, :, :] * 255
      img = img.astype('int32')
      plt.imshow(img)
      plt.axis('off')

  # tight_layout minimizes the overlap between 2 sub-plots
  fig.suptitle("epoch: {}, step: {}".format(epoch, step))
  plt.savefig('image_at_epoch_{:04d}_step{:04d}.png'.format(epoch, step))
  plt.show()

# Training loop. Display generated images each epoch

### START CODE HERE ###
epochs =200
### END CODE HERE ###

random_vector_for_generation = tf.random.normal(shape=[16, LATENT_DIM])
generate_and_save_images(decoder, 0, 0, random_vector_for_generation)

for epoch in range(epochs):
  print('Start of epoch %d' % (epoch,))

  # Iterate over the batches of the dataset.
  for step, x_batch_train in enumerate(training_dataset):
    with tf.GradientTape() as tape:
      ### START CODE HERE ### 
      reconstructed = vae(x_batch_train)
      # Compute reconstruction loss
      flattened_inputs = tf.reshape(x_batch_train, shape=[-1])
      flattened_outputs = tf.reshape(reconstructed, shape=[-1])
      loss = mse_loss(flattened_inputs, flattened_outputs) * 64 * 64 * 3
      loss += sum(vae.losses) 

    grads =tape.gradient(loss, vae.trainable_weights)
    optimizer.apply_gradients(zip(grads, vae.trainable_weights))
    ### END CODE HERE
    
    loss_metric(loss)

    if step % 10 == 0:
      display.clear_output(wait=False)    
      generate_and_save_images(decoder, epoch, step, random_vector_for_generation)
    print('Epoch: %s step: %s mean loss = %s' % (epoch, step, loss_metric.result().numpy()))





"""# pytorch autoencoder"""

class autoencoder(nn.Module):
    def __init__(self):
        super(autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 16, 3, stride=3, padding=1),  # b, 16, 10, 10
            nn.ReLU(True),
            nn.MaxPool2d(2, stride=2),  # b, 16, 5, 5
            nn.Conv2d(16, 8, 3, stride=2, padding=1),  # b, 8, 3, 3
            nn.ReLU(True),
            nn.MaxPool2d(2, stride=1)  # b, 8, 2, 2
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(8, 16, 3, stride=2),  # b, 16, 5, 5
            nn.ReLU(True),
            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),  # b, 8, 15, 15
            nn.ReLU(True),
            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),  # b, 1, 28, 28
            nn.Tanh()
        )
 
    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

ave=nn.Conv2d(1, 16, 3, stride=3, padding=1)
img= torch.from_numpy(data_contour[300])   
output=ave(img)

model = autoencoder().cuda()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,
                             weight_decay=1e-5)

for data in dataloader:
        img= data
        print(img.shape)

for epoch in range(num_epochs):
    for data in dataloader:
        img= data
        img = Variable(img).cuda()
        # ===================forward=====================
        output = model(img)
        loss = criterion(output, img)
        # ===================backward====================
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    # ===================log========================
    print('epoch [{}/{}], loss:{:.4f}'
          .format(epoch+1, num_epochs, loss.data[0]))
    if epoch % 10 == 0:
        pic = to_img(output.cpu().data)
        save_image(pic, './dc_img/image_{}.png'.format(epoch))

